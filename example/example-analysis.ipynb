{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using vOptGeneric, JuMP, Gurobi, DataFrames, VegaLite, Serialization, PlotlyJS, JMcDM, JSON\n",
    "\n",
    "include(\"../src/utils/plot.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten Laden\n",
    "result = deserialize(\"../results/result.jls\")[:,1:9]\n",
    "benchmark = deserialize(\"../results/benchmark.jls\")\n",
    "\n",
    "# Neue Spalte mit laufenden Nummern hinzufügen\n",
    "result.ID = 1:nrow(result)\n",
    "benchmark.ID = 1:nrow(benchmark)\n",
    "\n",
    "# Result und Benchmark auf beste Pareto Front Filtern\n",
    "filtered_result = filter(row -> row.Rang == 1.0, result)\n",
    "filtered_benchmark = filter(row -> row.Rang == 1.0, benchmark)\n",
    "filter!(row -> row.ID != 37, filtered_benchmark) # der Wert scheint ein falsch berechneter Ausreiser zu sein deshalb wird der hier entfernt\n",
    "filtered_result = combine(groupby(filtered_result, [:Dauer, :Kosten, :Belastung, :Modus]), first)\n",
    "filtered_benchmark = combine(groupby(filtered_benchmark, [:Dauer, :Kosten, :Belastung, :Modus]), first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging result and Benchmark into one DataFrame\n",
    "\n",
    "result_merged = select(filtered_result, :Dauer, :Kosten, :Belastung, :Modus, :ID) \n",
    "result_merged = unique(combine(groupby(result_merged, [:Dauer, :Kosten, :Belastung, :Modus]), first))\n",
    "result_merged[:, :Source] .= \"Result\"\n",
    "\n",
    "benchmark_merged = select(filtered_benchmark, :Dauer, :Kosten, :Belastung, :Modus, :ID) \n",
    "benchmark_merged[:, :Source] .= \"Benchmark\"\n",
    "\n",
    "# DataFrames zusammenführen\n",
    "merged_df = vcat(result_merged, benchmark_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rang hinzufügen\n",
    "merged_df[:, :Rang] = non_dominated_sort(merged_df)\n",
    "df = filter(row -> row.Rang == 1, merged_df)\n",
    "result_df = filter(row -> row.Source == \"Result\", df)\n",
    "benchmark_df = filter(row -> row.Source == \"Benchmark\", df)\n",
    "\n",
    "println(\"Benchmark: \", nrow(benchmark_df), \" nicht dominierte Punkte; \", nrow(benchmark_merged) - nrow(benchmark_df), \" dominierte Punkte\")\n",
    "println(\"Result: \",  nrow(result_df), \" nicht dominierte Punkte; \", nrow(result_merged) - nrow(result_df), \" dominierte Punkte\")\n",
    "println(\"Verhältnis: \", round(nrow(result_df) / nrow(df)*100, digits = 1), \"% der Lösungen aus NSGA-II\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_3d_scatter(filtered_benchmark)\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_3d_scatter(filtered_result, nothing, \"red\")\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anzeigen aller Punkte von Benchmark und Result\n",
    "plt = plot_3d_scatter(filtered_benchmark, filtered_result)\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_3d_scatter_zoom(filtered_benchmark, filtered_result)\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plot_3d_scatter(benchmark_df, result_df)\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df\n",
    "\n",
    "# Zuerst gruppierst du den DataFrame nach Dauer, Kosten und Modus\n",
    "grouped_df = groupby(df, [:Dauer, :Kosten, :Modus])\n",
    "\n",
    "# Nun pivotierst du die Daten basierend auf der Spalte 'Source', \n",
    "# wobei die Spalte 'Belastung' als Wert dient, der in den neuen Spalten angezeigt wird\n",
    "pivoted_df = unstack(df, [:Dauer, :Kosten, :Modus], :Source, :Belastung)\n",
    "\n",
    "function calc_percentage_diff(result, benchmark)\n",
    "    if ismissing(result) || ismissing(benchmark) || benchmark == 0.0\n",
    "        return missing\n",
    "    else\n",
    "        return ((result - benchmark) / benchmark) * 100\n",
    "    end\n",
    "end\n",
    "\n",
    "# Neue Spalte mit der prozentualen Abweichung hinzufügen\n",
    "pivoted_df[!, :Prozentuale_Abweichung] = calc_percentage_diff.(pivoted_df.Result, pivoted_df.Benchmark)\n",
    "\n",
    "# Den DataFrame nach der Dauer sortieren\n",
    "sort!(pivoted_df, :Dauer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics  # Für die mean Funktion\n",
    "\n",
    "# Berechne den Durchschnitt der prozentualen Abweichung, ignoriere missing-Werte\n",
    "durchschnitt = mean(skipmissing(pivoted_df.Prozentuale_Abweichung))\n",
    "medianwert = median(skipmissing(pivoted_df.Prozentuale_Abweichung))\n",
    "max = maximum(skipmissing(pivoted_df.Prozentuale_Abweichung))\n",
    "min = minimum(skipmissing(pivoted_df.Prozentuale_Abweichung))\n",
    "missing_result = count(ismissing, pivoted_df.Result)\n",
    "missing_benchmark = count(ismissing, pivoted_df.Benchmark)\n",
    "quantil_90 = round(quantile(skipmissing(pivoted_df.Prozentuale_Abweichung), 0.90), digits=4)\n",
    "\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "println(\"Der Durchschnitt der prozentualen Abweichung beträgt: \", durchschnitt, \"%\")\n",
    "println(\"Der Median der prozentualen Abweichung beträgt: \", medianwert, \"%\")\n",
    "println(\"Maximale Abweichung: \", max, \"%\")\n",
    "println(\"Minimale Abweichung: \", min, \"%\")\n",
    "println(\"Anzahl der Lösungen, die in Benchmark vorhanden sind aber nicht in Result: \", missing_result)\n",
    "println(\"Anzahl der Lösungen, die in Result vorhanden sind aber nicht in Benchmark: \", missing_benchmark)\n",
    "println(\"Anzahl der Lösungspaare: \", nrow(pivoted_df) - missing_result - missing_benchmark)\n",
    "println(\"Anzahl der gesamten Lösungen: \", nrow(pivoted_df))\n",
    "println(\"90% Quantil: \", quantil_90, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter(row -> row.Prozentuale_Abweichung !== missing, pivoted_df)\n",
    "reordered_df = select(filtered_df, :Dauer, :Modus, :Kosten, :Benchmark, :Result, :Prozentuale_Abweichung)\n",
    "reordered_df.Prozentuale_Abweichung = string.(round.(filtered_df.Prozentuale_Abweichung, digits=2)) .* \"%\"\n",
    "reordered_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
